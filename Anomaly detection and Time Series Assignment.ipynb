{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c151bd1",
   "metadata": {},
   "source": [
    "# Anomaly detection and Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2251564",
   "metadata": {},
   "source": [
    "**1. What is Anomaly Detection? Explain its types (point, contextual, and\n",
    "collective anomalies) with examples?**\n",
    "\n",
    "- It is the process of finding data points that deviate from normal patterns.\n",
    "\n",
    "1. **Point Anomaly** – A single data point is unusual.\n",
    "   *Example: A sudden ₹5,00,000 transaction on a card that usually spends ₹5,000.*\n",
    "\n",
    "2. **Contextual Anomaly** – Data is abnormal in a specific context (time, place, situation).\n",
    "   *Example: 30°C temperature in winter.*\n",
    "\n",
    "3. **Collective Anomaly** – A group/sequence of points is abnormal together.\n",
    "   *Example: Continuous drop in network traffic for 10 minutes.*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cbea28",
   "metadata": {},
   "source": [
    "**2. Compare Isolation Forest, DBSCAN, and Local Outlier Factor in terms of\n",
    "their approach and suitable use cases.?**\n",
    "\n",
    "- **Isolation Forest (iForest):**\n",
    "Isolation Forest detects anomalies by isolating data points using random splits. Points that are easier to isolate (require fewer splits) are considered anomalies. It is effective for high-dimensional and large datasets, and works well when anomalies are globally different from normal data.\n",
    "*Use case:* Credit card fraud detection.\n",
    "\n",
    "- **DBSCAN (Density-Based Spatial Clustering of Applications with Noise):**\n",
    "DBSCAN identifies clusters based on point density. Points that do not belong to any dense cluster are treated as outliers. It works well for datasets with clusters of arbitrary shapes and is sensitive to parameter settings.\n",
    "*Use case:* Detecting unusual GPS locations.\n",
    "\n",
    "- **Local Outlier Factor (LOF):**\n",
    "LOF detects anomalies by comparing the local density of a point to the density of its neighbors. Points with significantly lower density than their neighbors are considered outliers. It is useful for detecting local anomalies in datasets with varying densities.\n",
    "*Use case:* Identifying unusual behavior within a subgroup of customers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999d17d",
   "metadata": {},
   "source": [
    "**3. What are the key components of a Time Series? Explain each with one\n",
    "example**\n",
    "\n",
    "1. Trend (T):\n",
    "\n",
    "- Represents the long-term movement or direction in the data over time.\n",
    "\n",
    "- Shows whether the values are generally increasing, decreasing, or constant.\n",
    "\n",
    "- Example: The gradual rise in global average temperatures over decades.\n",
    "\n",
    "2. Seasonality (S):\n",
    "\n",
    "- Represents regular, repeating patterns or fluctuations within a fixed period (e.g., daily, monthly, yearly).\n",
    "\n",
    "- Example: Increased ice cream sales every summer.\n",
    "\n",
    "3. Cyclic Component (C):\n",
    "\n",
    "- Represents long-term fluctuations caused by economic or business cycles, not fixed in length.\n",
    "\n",
    "- Example: Economic boom and recession cycles affecting stock market prices over several years.\n",
    "\n",
    "4. Irregular / Random Component (I):\n",
    "\n",
    "- Represents unpredictable, random variations or noise in the data.\n",
    "\n",
    "- Example: Sudden spike in flight cancellations due to a natural disaster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61b8e43",
   "metadata": {},
   "source": [
    "**4. Define Stationary in time series. How can you test and transform a\n",
    "non-stationary series into a stationary one?**\n",
    "\n",
    "- A **stationary time series** is one whose **mean, variance, and autocorrelation remain constant over time**, without trends or seasonal patterns. \n",
    "- Stationarity is important because many forecasting models, like ARIMA, assume a stable underlying process. To check stationarity, we can use **visual inspection** or statistical tests like **ADF** and **KPSS**.\n",
    "- If a series is non-stationary, it can be transformed using **differencing, log transformations, detrending, or seasonal adjustment** to stabilize its statistical properties, making it suitable for accurate modeling and forecasting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9388e88",
   "metadata": {},
   "source": [
    "**5. Differentiate between AR, MA, ARIMA, SARIMA, and SARIMAX models in\n",
    "terms of structure and application.**\n",
    "\n",
    "\n",
    "- **AR, MA, ARIMA, SARIMA, and SARIMAX** are time series forecasting models with different structures and applications.\n",
    "- The **AR (AutoRegressive) model** predicts values using past observations and is suitable for stationary series.\n",
    "- The **MA (Moving Average) model** uses past forecast errors to make predictions, also for stationary series. \n",
    "-**ARIMA** combines AR and MA with differencing to handle non-stationary data with trends.\n",
    "- **SARIMA** extends ARIMA by adding seasonal components, making it ideal for series with both trend and seasonality.\n",
    "- Finally, **SARIMAX** further extends SARIMA by incorporating exogenous variables, allowing the model to account for external factors affecting the time series.\n",
    "- These models are selected based on the presence of trend, seasonality, and external influences in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e4c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Load a time series dataset (e.g., AirPassengers), plot the original series, and decompose it into trend, seasonality, and residual components.\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.datasets import get_rdataset\n",
    "\n",
    "# Load AirPassengers dataset\n",
    "data = get_rdataset('AirPassengers').data\n",
    "data['Month'] = pd.to_datetime(data['time'], format='%Y-%m')\n",
    "data.set_index('Month', inplace=True)\n",
    "ts = data['value']\n",
    "\n",
    "# Plot original time series\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(ts, color='blue')\n",
    "plt.title('Original AirPassengers Time Series')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Passengers')\n",
    "plt.show()\n",
    "\n",
    "# Decompose the time series\n",
    "decomposition = seasonal_decompose(ts, model='multiplicative', period=12)\n",
    "\n",
    "# Plot decomposed components\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(4,1,1)\n",
    "plt.plot(ts, label='Original')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "plt.plot(decomposition.trend, label='Trend', color='orange')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "plt.plot(decomposition.seasonal, label='Seasonality', color='green')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "plt.plot(decomposition.resid, label='Residuals', color='red')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e38d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Apply Isolation Forest on a numerical dataset (e.g., NYC Taxi Fare) to detect anomalies. Visualize the anomalies on a 2D scatter plot\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Load a sample NYC Taxi Fare dataset\n",
    "# Here, we generate a small synthetic example for demonstration\n",
    "# Replace with actual CSV file if available\n",
    "data = pd.DataFrame({\n",
    "    'passenger_count': [1, 2, 1, 3, 1, 2, 100, 1, 2, 3, 2, 1, 5, 1, 3, 2, 0, 2],\n",
    "    'fare_amount': [10, 15, 12, 20, 8, 14, 500, 11, 13, 18, 15, 9, 25, 12, 19, 16, 2, 14]\n",
    "})\n",
    "\n",
    "# Fit Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "data['anomaly'] = iso_forest.fit_predict(data)\n",
    "\n",
    "# -1 for anomalies, 1 for normal points\n",
    "anomalies = data[data['anomaly'] == -1]\n",
    "normal = data[data['anomaly'] == 1]\n",
    "\n",
    "# Visualize anomalies on a 2D scatter plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(normal['passenger_count'], normal['fare_amount'], c='blue', label='Normal')\n",
    "plt.scatter(anomalies['passenger_count'], anomalies['fare_amount'], c='red', label='Anomaly')\n",
    "plt.xlabel('Passenger Count')\n",
    "plt.ylabel('Fare Amount')\n",
    "plt.title('Anomaly Detection using Isolation Forest')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b42cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.Train a SARIMA model on the monthly airline passengers dataset. Forecast the next 12 months and visualize the results\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.datasets import airpassengers\n",
    "\n",
    "# Load AirPassengers dataset\n",
    "dataset = airpassengers.load_pandas()\n",
    "ts = dataset.data['AirPassengers']\n",
    "ts.index = pd.date_range(start='1949-01', periods=len(ts), freq='M')\n",
    "\n",
    "# Split data (optional, here we use full dataset)\n",
    "train = ts\n",
    "\n",
    "# Define SARIMA model\n",
    "# SARIMA(p,d,q)(P,D,Q,s)\n",
    "# Common starting values: p=1, d=1, q=1, P=1, D=1, Q=1, s=12 (monthly data)\n",
    "model = SARIMAX(train, \n",
    "                order=(1,1,1), \n",
    "                seasonal_order=(1,1,1,12), \n",
    "                enforce_stationarity=False, \n",
    "                enforce_invertibility=False)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "# Forecast next 12 months\n",
    "forecast = results.get_forecast(steps=12)\n",
    "forecast_index = pd.date_range(start=ts.index[-1] + pd.DateOffset(months=1), periods=12, freq='M')\n",
    "forecast_series = pd.Series(forecast.predicted_mean.values, index=forecast_index)\n",
    "forecast_ci = forecast.conf_int()\n",
    "\n",
    "# Plot original series and forecast\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(ts, label='Original', color='blue')\n",
    "plt.plot(forecast_series, label='Forecast', color='red')\n",
    "plt.fill_between(forecast_index, \n",
    "                 forecast_ci.iloc[:,0], \n",
    "                 forecast_ci.iloc[:,1], color='pink', alpha=0.3)\n",
    "plt.title('SARIMA Forecast for AirPassengers')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Passengers')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2873588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Apply Local Outlier Factor (LOF) on any numerical dataset to detect anomalies and visualize them using matplotlib\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Sample numerical dataset (can replace with real dataset)\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': [10, 12, 11, 13, 12, 14, 100, 11, 13, 12, 15, 12, 14, 13, 12, 11],\n",
    "    'Feature2': [20, 22, 21, 23, 22, 24, 200, 21, 23, 22, 25, 22, 24, 23, 22, 21]\n",
    "})\n",
    "\n",
    "# Apply LOF\n",
    "lof = LocalOutlierFactor(n_neighbors=5, contamination=0.1)\n",
    "data['anomaly'] = lof.fit_predict(data)  # -1 = anomaly, 1 = normal\n",
    "\n",
    "# Separate normal points and anomalies\n",
    "normal = data[data['anomaly'] == 1]\n",
    "anomalies = data[data['anomaly'] == -1]\n",
    "\n",
    "# Visualize anomalies\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(normal['Feature1'], normal['Feature2'], c='blue', label='Normal')\n",
    "plt.scatter(anomalies['Feature1'], anomalies['Feature2'], c='red', label='Anomaly')\n",
    "plt.xlabel('Feature1')\n",
    "plt.ylabel('Feature2')\n",
    "plt.title('Anomaly Detection using LOF')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df10410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.You are working as a data scientist for a power grid monitoring company. Your goal is to forecast energy demand and also detect abnormal spikes or drops in real-time consumption data collected every 15 minutes. The dataset includes features like timestamp, region, weather conditions, and energy usage. Explain your real-time data science workflow:\n",
    "#● How would you detect anomalies in this streaming data (Isolation Forest / LOF / DBSCAN)?\n",
    "#● Which time series model would you use for short-term forecasting (ARIMA / SARIMA / SARIMAX)?\n",
    "#● How would you validate and monitor the performance over time?\n",
    "#● How would this solution help business decisions or operations?\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Generate synthetic dataset\n",
    "# ---------------------------\n",
    "np.random.seed(42)\n",
    "date_rng = pd.date_range(start='2025-01-01', end='2025-01-07', freq='15T')  # 15-min intervals\n",
    "n = len(date_rng)\n",
    "energy_usage = 50 + 10*np.sin(np.arange(n)*2*np.pi/96) + np.random.normal(0, 3, n)  # daily seasonality\n",
    "weather_temp = 20 + 5*np.sin(np.arange(n)*2*np.pi/96) + np.random.normal(0,1,n)      # synthetic weather\n",
    "region = np.random.choice(['North','South'], size=n)\n",
    "\n",
    "data = pd.DataFrame({'timestamp': date_rng, 'region': region, \n",
    "                     'temperature': weather_temp, 'energy_usage': energy_usage})\n",
    "data.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Introduce some anomalies\n",
    "data.loc[data.sample(5).index, 'energy_usage'] *= 2\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Anomaly Detection with Isolation Forest\n",
    "# ---------------------------\n",
    "features = ['energy_usage','temperature']\n",
    "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "data['anomaly'] = iso_forest.fit_predict(data[features])  # -1 = anomaly, 1 = normal\n",
    "\n",
    "# Visualize anomalies\n",
    "plt.figure(figsize=(12,6))\n",
    "normal = data[data['anomaly']==1]\n",
    "anomaly = data[data['anomaly']==-1]\n",
    "plt.plot(normal.index, normal['energy_usage'], label='Normal')\n",
    "plt.scatter(anomaly.index, anomaly['energy_usage'], color='red', label='Anomaly', s=50)\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Energy Usage')\n",
    "plt.title('Anomaly Detection with Isolation Forest')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Short-term Forecasting with SARIMAX\n",
    "# ---------------------------\n",
    "# SARIMAX uses energy_usage as endogenous and temperature as exogenous\n",
    "train = data['energy_usage'][:-96]  # last day for testing\n",
    "exog_train = data['temperature'][:-96]\n",
    "test = data['energy_usage'][-96:]   # last day\n",
    "exog_test = data['temperature'][-96:]\n",
    "\n",
    "# Define SARIMAX model (daily seasonality, 96 periods per day)\n",
    "model = SARIMAX(train, exog=exog_train, order=(1,1,1), seasonal_order=(1,1,1,96),\n",
    "                enforce_stationarity=False, enforce_invertibility=False)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "# Forecast next 96 periods (1 day ahead)\n",
    "forecast = results.get_forecast(steps=96, exog=exog_test)\n",
    "forecast_values = forecast.predicted_mean\n",
    "forecast_ci = forecast.conf_int()\n",
    "\n",
    "# Plot forecast vs actual\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(data.index, data['energy_usage'], label='Actual')\n",
    "plt.plot(test.index, forecast_values, color='red', label='Forecast')\n",
    "plt.fill_between(test.index, forecast_ci.iloc[:,0], forecast_ci.iloc[:,1], color='pink', alpha=0.3)\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Energy Usage')\n",
    "plt.title('SARIMAX Short-Term Forecasting')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
